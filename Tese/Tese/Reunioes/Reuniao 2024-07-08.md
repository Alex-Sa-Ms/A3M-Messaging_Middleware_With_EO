# Conclusões
## Flag "throwIfNone"
- A flag `throwIfNone` quando definida num método, tem como objetivo a emissão de uma exceção na ausência de links estabelecidos e por estabelecer. Isto permite que peças (dinâmicas) da topologia, responsáveis por iniciar processos de estabelecimento de links e que nunca receberão tais pedidos, não fiquem eternamente bloqueadas. 
- Como os sockets são thread-safe, a situação de falta de links, poderia ser resolvida por uma outra thread, no entanto, por conveniência e para facilitar a programação, pensou-se no uso desta flag. 
- Este comportamento é invocado por uma flag já que uma peça fixa da topologia, como um servidor, aguarda que outras peças iniciem o processo de estabelecimento de link, sendo então desejável que este tipo de peças possa ficar bloqueada até que um link seja estabelecido e que não seja emitida uma exceção na ausência de links.
- A flag é primariamente empregada pelos métodos genéricos `waitForLink()` e `waitForAvailableLink()` que esperam pelo estabelecimento de um link ou pela disponibilidade para envio de um link estabelecido, respetivamente.
 - Esta flag pode ser utilizada também em métodos de envio e receção.
	 - O `AbstractSocket` pode ter uma implementação base dos métodos de envio e receção com o argumento `throwIfNone`. Estas implementações devem emitir a exceção `UnsupportedOperationException`. Se for decidido que se pretende implementar esse método, então faz-se o @Override e expõe-se esses métodos na classe *wrapper* do Socket.
## Link retries
### Solução 1
- Permitir criar sockets antes de iniciar a instância. Ao invocar `start()`, a instância passa a processar mensagens recebidas que incluem pedidos de ligação. Deste modo, evita-se rejeitar pedidos de ligação porque a criação do socket está atrasada.
	```
		// create middleware instance
		A3MMiddleware middleware = A3MMiddleware.new("node1","192.168.1.99", 12345); 
		// create socket
		RepSocket server = RepSocket.create("server", middleware);
		// starts middleware
		middleware.start();
	```
- O problema desta solução é não cobrir sockets que são criados após a instância ser iniciada.
### Solução 2 (final)
- Inclui a proposta da solução 1.
- Contempla retries de pedidos de ligação.
- O ZeroMQ não parece ter limites de pedidos de ligação, mas não custa incluir como uma opção base que tem como valor default "infinito". Possui, no entanto, um mínimo e máximo para o timeout entre cada pedido. A cada falha no pedido, o valor do timeout aumenta exponencialmente até ao valor máximo se este tiver sido definido. Se o valor máximo não tiver sido definido, o valor de timeout permanece igual.
	- Não deve ser necessário valores de timeouts aleatórios para proteger contra thundering herd, mas pode ser algo a mencionar na tese.
- As novas tentativas de ligação devem ser executadas pela única thread do middleware (a reader thread). Para isto é necessário que os sockets tenham um método privado, para não ser exposto às subclasses, que aquando da receção de uma resposta negativa a um pedido de ligação por ausência do socket destino, permite o socket criar um evento `LinkRetryEvent` e colocá-lo na queue de eventos a serem realizados pela reader thread.
	- Um evento do tipo `SendMsgEvent` que permitiria agendar o envio de uma mensagem parece uma solução válida e útil até para outras situações, no entanto, é importante que antes de reenviar o pedido de ligação se verifique que o socket não se encontra fechado e que o cliente não cancelou o processo de ligação com o destino em questão (através do método `unlink()`).
	- Para realizar estas verificações, a reader thread, no momento de execução do evento `LinkRetryEvent` apenas necessita de executar o método `linkRetry(sid : SocketIdentifier)` do socket que se encontra incluído no objeto do evento.
	- O método `linkRetry(sid : SocketIdentifier)` fará todas as verificações necessárias: (1) socket não se encontra fechado; (2) link em questão encontra-se num estado de aguardar retry.
	- Se o método tiver visibilidade "default" pode evitar-se que seja visto por classes que não devem, mas não deixa de ser poder ser exposto se uma subclasse do `AbstractSocket` for criada dentro do meu package.
## Expor eventos do socket
- A exposição de eventos do socket como "Link estabelecido com X", "Link recusado por X", "Sem links", etc.
- No caso de ser necessário e mesmo relevante a exposição destes eventos, estes podem ser expostos a partir de um método diferente do `receive()` de mensagens. Isto permite evitar que a programação do fluxo normal seja complicada desnecessariamente. 
- No fundo, isto poderia ser um *log* do socket.
- Neste momento, esta funcionalidade não aparenta ser necessária. ZeroMQ e NNG não possuem nada parecido com esta funcionalidade.

## Wait for link availability (to send)

Ensuring a link is available for sending a message is crucial for developing blocking send methods across various socket types. While some socket implementations can use a generic send method that includes the waiting functionality, others require a method that exclusively waits for sending availability, allowing the socket to decide if and what message should be sent.

Therefore, in addition to the generic blocking send method, two key functionalities are needed: waiting for a specific link to become available (`waitForLinkAvailability(sid: SocketIdentifier)`) and waiting for any link to become available (`waitForAvailableLink()`).

<!-- The "waiting" capability will be provided by a flow control coordinator, while the actual credits of each link will be managed by a flow control manager. This enables the separation of the concerns of coordinating threads and managing the flow control. In this section, we will be talking about different implementations of flow control coordinators and how a flow control coordinator is employed alongside a flow control manager. -->  

### Waiting for a Specific Link

Waiting for a specific link is a straightforward problem, commonly referred to as the Producer-Consumer problem. This can be easily solved using a single lock condition. When the link has credits, threads can return immediately. If the balance is insufficient, threads must wait using the lock condition. When credits are replenished, the lock condition is used to signal the appropriate number of threads that can be satisfied.

### Waiting for Any Link

The complexity increases when waiting for any link to become available. The main challenges are related to fairness, starvation and the thundering herd problem.

1. **Fairness/Starvation**: The primary issue is avoiding the prioritization of link-specific[^1] or general threads[^2].  Evenly distributing link credits between waiting threads and preventing threads from never being signaled depends on the fairness of the signaling mechanism chosen by the client.

2. **Thundering Herd**: This problem is addressed by avoiding signaling threads that cannot perform work, thereby preventing unnecessary context switches that degrade performance. Signaling a thread when the return condition cannot be met results in two unnecessary context switches since the thread needs to wait again.

[^1] Link-specific threads are threads interested in a single link.
[^2] General threads are threads interested in any link.

### Basic Implementation

A basic implementation might use a lock condition per link for link-specific waiting operations and a general lock condition for any link waiting operations. When a link's credits are replenished, the `signalAll()` method of both conditions could be invoked. Signaled threads would then check the link balance and return if is positive; if not, they would wait again. This approach, however, is not ideal due to potential races for credits, increased lock contention, pointless context switches, and starvation of slower threads.

### Advanced Implementations

The key to address the mentioned challenges is to use requests. There are two types of requests: link-specific and general. With each request corresponding to a thread's intention to wait for sending availability, the thundering herd problem is solved by only signaling the amount of threads that can be satisfied by the credit balance that each link allows. Regarding the starvation and fairness problems, two solutions are provided for the client to choose from: a *fair-ish* version and an unfair version. 

### Fair-ish implementation

To address the fairness and starvation problems, the devised solution involves requests that offer a sense of order. This order is achieved by giving to each request a ticket number. Each request is then placed in an appropriate queue depending on its type. Each link has its own queue of link-specific requests, and general requests are kept in a common queue. When the credits of a link are increased, it signals waiting threads based on the ticket numbers of the requests. The link peeks at the first ticket number of both its own link-specific requests queue and the general requests queue. The queue with the smallest ticket number (or with requests) dictates which type of waiting thread should be signaled. This approach solves the fairness/starvation problem between different types of threads. To ensure fairness among threads of the same type, a fair version of the lock is employed.

A "waiting" thread can only return when the consumption of a credit is possible, i.e., when the link in question has positive credits. However, to prevent new "waiting" threads from stealing credits from threads already waiting, a new "waiting" thread can only return immediately if the link credits exceed the number of requests. Since this immediate return is allowed, the implementation is not completely fair, but for efficiency purposes, this solution seemed acceptable as it prevents two unnecessary context switches: the first when threads enter the waiting queue; and the second when they are signaled shortly after.

### Unfair Implementation

The unfair implementation is much more relaxed on the fairness and starvation problems. Apart from interleaving (when possible[^3]) signals of link-specific and general threads, there is no attempt in signaling threads in the order in which the requests were issued. Furthermore, credit stealing is not prevented. A thread that in the fair-ish version would be queued, due to the insufficient amount of credits to satisfy both the thread in question and the threads already waiting, can consume a credit instantaneously.

[^3] Interleaving is only possible when there are requests of both types.
<span style="color:red">Faz sentido fazer interleaving por link especifico ou faria mais sentido fazer interleaving a nível geral? Isto porque </span>
<span style="color:red">Usar algoritmo de sinalizacao em funcao do nº de threads a sinalizar? Na fair version nao da por causa da ordem.</span>
### Credit reservation

The problems that surround the "waiting for availability" dilema are not over. 

The first problem is that a thread that had its "waiting" method invocation return successfully should have the right to send a message to the link that proved to be available whenever it intends to. For this to be possible, credits must be reserved. The reservation of the credits is done by consuming the credit preemptively, as you may have noticed from the advanced implementations' explanations. If the credits were not reserved, a thread that after the return of the waiting method did not consume the credit immediately[^4] could have its credit stolen by another thread[^5].

The second problem arises with credits being consumed preemptively. A thread after waiting for availability may decide that it does not want to send a message. In this case, a `releaseCredit()` method must be used to "release" the credit and to signal another thread. Releasing credits cannot be done by simply increasing the credits of the link, as this would open a possibility for farming credits. To prevent farming, requests will now have three states: new, unsettled and settled. A request is new when created, becomes unsettled when a thread secures a credit, and becomes settled (deleted) when a thread effectively acquires or releases a credit. By making the `releaseCredit()` fail when there aren't unsettled requests, the farming problem is thereby prevented. As for the acquisition it is done by invoking `acquireCredit()`, which can also fail[^6] for the same reason.

[^4] Until the release of the socket lock.
[^5] The positive credits that result from an increase in credit balance results in signaling new threads. If a credit is not reserved, a new thread could be signaled, resulting in a race for that credit. 
[^6] The failing of the `acquireCredit()` method does not really matter, as the consumption of credits is done by the "wait...()" methods.

<p style="color:red">Usar um coordenador que nao pode atualizar diretamente os créditos pode resultar na falha de um envio pq creditos foram reservados no coordenador mas entretanto houve reducao de creditos que passou o nº de creditos efetivo do link para negativo ou mesmo 0. Se o coordenador estiver desligado entao poderia nao fazer sentido aceitar que as mensagens fossem enviadas já que o crédito efetivo nao tinha sido alterado para manifestar as reservas dos creditos, no entanto, se estiver ligado, a reserva é feita atraves do consumo do credito, indicando que a mensagem é como se tivesse sido efetivamente enviada.</p>

### Exposing the functionality
<span style="color:orange">TODO:</span>
<span style="color:red">
<p> Como enviar mensagens que não devem consumir créditos?
<p> Talk about `releaseSendCredit()`, `sendMsg(message : Msg, reservedCredit : boolean)`
</span>
The exposure of this functionality might even be useful to a client depending on the semantics of the socket[^a].

[^a] The process of safely exposing the functionality is elaborated further ahead. 


Estava nos 47:23 da gravacao.